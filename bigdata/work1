#MapReduce 预习知识点概述

##1.1MapReduce 的定义： MapReduce 是一个分布式运算程序的编程框架，可用于大型商用硬件集群中（成千上万的节点）对海量数据（多个兆字节数据集）实施可靠的，高容错的分布式计算框架。

###1.2MapReduce 的核心功能： MapReduce 可以把用户编写的业务逻辑代码和自带默认组件整合成一个完整的分布式运算程序，并发运行在一个 Hadoop 集群上。

##1.3MapReduce 的优缺点： ###1.3.1 优点： （1）MapReduce 易于编程

（2）良好的扩展性

（3）高容错性

（4）适合 PB 级以上海量的数据进行离线处理

###1.3.2 缺点

MapReduce 不擅长做实时计算，流式计算，DAG（有向图计算）

##1.4MapReduce 基本原理

分布式的运算程序往往需要分成两个阶段

（1）第一个阶段的 maptask 并发实例，完全并行运行，互不相干。

（2）第二个阶段的 reduce task 并发实例互不相干,但是他们的数据依赖于上一个阶段的所有maptask并发实例的输出。

（3）MapReduce编程模型只能包含一个Map阶段和一个Reduce阶段，如果用户的业务逻辑非常复杂，那就只能多个MapReduce程序，穿行运行。

##1.5MapReduce进程

一个完整的 MapReduce 程序在分布式运行时有三类实例进程：

（1）MrAppMaster：负责整个程序的过程调度及状态协调

（2）MapTask：负责 Map 阶段的整个数据处理流程。

（3）ReduceTask：负责 Reduce 阶段的整个数据处理流程。

##1.6MapReduce编程规范

###1.6.1Mapper

Mapper继承父类

输入数据是KV对

业务逻辑写在map方法中

输出数据是KV对

map()方法（MapTask进程）对每一个<K,V>调用一次

###1.6.2Reducer

Reducer继承父类

输入数据是KV

业务逻辑写在reduce方法中

ReduceTask进程对每一组相同k的<k,v>组调用一次reduce()方法

###1.6.3Driver 用于提交整个程序到YARN集群，提交的是 封装了MapReduce程序相关运行参数的job对象

##1.7MapReduce编辑模型

###1.7.1模型简介

MapReduce是一种思想或是一种编程模型。对Hadoop来说，MapReduce是一个分布式计算框架，是它的一个基础组件。当配置好Hadoop集群时，MapReduce已包含在内。

MapReduce编程模型主要由两个抽象类构成。即Mapper类和Reducer类。

Mapper用以对切分过的原始数据进行处理，Reducer则对mapper的结果进行汇总，得到最后的输出结果。对软件开发人员而言，只需要分别实现Mao函数和

Reduce函数即可以编写MapReduce程序，这一点和编写过程函数一样简单。

###1.7.2MapReduce简单模型

对于某些任务来说，可能并一定需要Reduce过程。所以MapReduce也有简单的模型，该模型只有Mapper过程，由Mapper产生的数据直接写入HDFS。

###1.7.3MapReduce复杂模型

对于大部分任务来说，都是需要Reduce过程，并且由于任务繁重，会启动多个Reduce（默认为1，根据任务量可由用户自己设定）来进行汇总。如果只用一个Reduce计算所有Mapper的结果，会导致单个Reduce负载过于繁重，成为性能的瓶颈，大大增加任务的运行周期。

##1.8MapReduce数据流

数据以不同的形式在不同的节点之间流动，即经过本节点的分析处理，以另外一种形式进入下一个节点，从而得出最终结果。

###1.8.1分片，格式化数据源（InputFormat）

InputFormat主要有两个任务，一个是对源文件进行分片，并确定Mapper的数量：另一个是对各分片进行格式化，处理成<key，value>形式的数据流并给Mapper。

###1.8.2Map过程

Mapper接收<key，value>形式的数处理成据，并处理成<key，value>形式的数据。

###1.8.3Comblner过程

每一个map（）都可能会产生大量的本地输出，Comblner（）的作用就是对 map（）端的输出先做一次合并，以减少在Map和Reduce结点之间的数据传输量，提高I/O性能，是MapReduce的一种优化手段之一。

###1.8.4 Shuffle过程

Shuffle过程是指Mapper产生的直接输出结果，经过一系列的处理，成为最终的Reducer直接输入数据为止的整个过程，这一过程也是MapReduce的核心过程。

###1.8.5Reduce过程

Reduce接收<key，{value list}>形式的数据流，形成<key，value>形式的数据输出，输出数据直接写入HDFS，具体的处理过程可由用户定义。

##1.9MapReduce任务运行流程

###1.9.1MRv2基本组成

客户端

MRAppMaster

Map Task和Reduce Task

###1.9.2Yarn基本组成

Resource Manager

NodeManager

ApplicationsMaster

container

###1.9.3任务流程

（1) client 向 ResourceManager 提交任务。

（2) ResourceManager 分配该任务的第一个 container ，并通知相应的 NodeManager 启动 MRAppMaster 。

（3) NodeManager 接收命令后，开辟一个 container 资源空间，并在 container 中启动相应的 MRAppMaster 。

(4) MRAppMaster 启动之后，第一步会向 ResourceManager 注册，这样用户可以直接通过 MRAppMaster 监控任务的运行状态；之后则直接由 MRAppMaster 调度任务运行，重复(5)~(8)，直到任务结束。

(5) MRAppMaster 以轮询的方式向 ResourceManager 申请任务运行所需的资源。

(6）一旦 ResourceManager 配给了资源， MRAppMaster 便会与相应的 NodeManager 通信，让它划分 Container 并启动相应的任务（ MapTask 或 Reduce Task )。个都有可每

(7) NodeManager 准备好运行环境，启动任务。

(8）各任务运行，并定时通过 RPC 协议向 MRAppMaster 汇报自己的运行状态和进度。 MRAppMaster 也会实时地监控任务的运行，当发现某个 Task 死或失败时，便杀死它重新启动任务。

(9）任务完成， MRAppMaster 向 ResourceManager 通信，注销并关闭自己。